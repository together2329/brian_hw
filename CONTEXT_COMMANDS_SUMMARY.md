# Brian Coder Context Management Commands

## êµ¬í˜„ ì™„ë£Œ ê¸°ëŠ¥

### 1. `/context` - í† í° ì‚¬ìš©ëŸ‰ ì‹œê°í™”
Claude Code ìŠ¤íƒ€ì¼ì˜ ì‹¤ì‹œê°„ í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ

**ì‚¬ìš©ë²•:**
```
/context        # ì¼ë°˜ ëª¨ë“œ
/context debug  # ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸ ì •ë³´ í¬í•¨)
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
 Context Usage
 â› â› â› â›€ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   openai/gpt-oss-120b Â· 42.7k/65.5k tokens (65.1%) [API actual]
 â› â› â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   â› System (includes tools, memory, graph): 13.2k tokens (20.2%)
 â› â› â› â› â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   â› Messages (user/assistant): 29.5k tokens (45.0%)
 â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   â›¶ Free space: 22.8k (34.9%)

ğŸ’¡ Tip: Use /clear to free up context
ğŸ’¡ Tip: Use /compact to summarize old messages
```

**ë””ë²„ê·¸ ëª¨ë“œ ì¶”ê°€ ì •ë³´:**
```
=== DEBUG INFO ===
  llm_client.last_input_tokens: 26,666
  actual_total: 26,666
  tracker.system_prompt_tokens: 13,215
  tracker.messages_tokens: 29,464
  message_stats:
    total_messages: 4
    with_actual_tokens: 2
    with_estimated_tokens: 2
  config.MAX_CONTEXT_CHARS: 262,144
  tracker.max_tokens: 65,536
==================
```

**íŠ¹ì§•:**
- âœ… API ì‹¤ì œ í† í° ìˆ˜ ì‚¬ìš© (API í˜¸ì¶œ í›„)
- âœ… ì €ì¥ëœ í† í° ë©”íƒ€ë°ì´í„° í™œìš©
- âœ… Estimationì€ í•„ìš”í•œ ê²½ìš°ë§Œ ì‚¬ìš©
- âœ… `[API actual]` vs `[estimated]` êµ¬ë¶„ í‘œì‹œ

---

### 2. `/clear` - ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
ëª¨ë“  ëŒ€í™” ê¸°ë¡ì„ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì‹œì‘

**ì‚¬ìš©ë²•:**
```
/clear
```

**ë™ì‘:**
1. messagesë¥¼ system promptë§Œ ë‚¨ê¸°ê³  ì´ˆê¸°í™”
2. context_tracker ì—…ë°ì´íŠ¸ (messages_tokens = 0)
3. conversation_history.json ì €ì¥ (ë¹ˆ ëŒ€í™”)

**ì¶œë ¥:**
```
âœ… Conversation history cleared.
```

**Before:**
```
 Context Usage
 â› â› â› â› â› â› â› â› â› â›¶   openai/gpt-oss-120b Â· 78.8k/65.5k tokens (120.3%)
 â› â› â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   â› System: 13.2k tokens (20.2%)
 â› â› â› â› â› â› â› â›¶ â›¶ â›¶   â› Messages: 65.6k tokens (100.1%)
```

**After:**
```
 Context Usage
 â› â› â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   openai/gpt-oss-120b Â· 13.2k/65.5k tokens (20.2%)
 â› â› â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   â› System: 13.2k tokens (20.2%)
 â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   â› Messages: 0 tokens (0%)
```

---

### 3. `/compact` - ëŒ€í™” ê¸°ë¡ ì••ì¶•
ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ìš”ì•½í•˜ê³  ìµœê·¼ ë©”ì‹œì§€ë§Œ ìœ ì§€

**ì‚¬ìš©ë²•:**
```
/compact                                    # ê¸°ë³¸ ìš”ì•½
/compact Focus on technical decisions      # ì»¤ìŠ¤í…€ ìš”ì•½ ì§€ì‹œ
```

**ë™ì‘:**
1. ë©”ì‹œì§€ê°€ 10ê°œ ì´ìƒì¼ ë•Œë§Œ ì‘ë™
2. ìµœê·¼ 5ê°œ ë©”ì‹œì§€ ìœ ì§€
3. ë‚˜ë¨¸ì§€ ë©”ì‹œì§€ë¥¼ LLMìœ¼ë¡œ ìš”ì•½
4. messages ì¬êµ¬ì„±: [system, summary, recent_5]
5. context_tracker ì—…ë°ì´íŠ¸
6. conversation_history.json ì €ì¥

**ì¶œë ¥:**
```
âœ… Conversation compacted. Kept 7 messages.
```

**ì••ì¶• íš¨ê³¼ ì˜ˆì‹œ:**

**Before:**
- 51 messages
- 65.6k tokens in messages

**After:**
- 7 messages (system + summary + 5 recent)
- ~20k tokens in messages (ì•½ 70% ì ˆê°)

---

## í† í° ë©”íƒ€ë°ì´í„° ì‹œìŠ¤í…œ

### ìë™ ì €ì¥
ëª¨ë“  assistant ì‘ë‹µì— ì‹¤ì œ API í† í° ì‚¬ìš©ëŸ‰ ì €ì¥:

```json
{
  "role": "assistant",
  "content": "...",
  "_tokens": {
    "input": 13663,
    "output": 222,
    "total": 13885
  }
}
```

### conversation_history.json
- ëŒ€í™” ê¸°ë¡ê³¼ í•¨ê»˜ í† í° ì •ë³´ ìë™ ì €ì¥
- ë‹¤ìŒ ì„¸ì…˜ì—ì„œ ë¡œë“œ ì‹œ ì •í™•í•œ í† í° ìˆ˜ ë³µì›
- `/context` ëª…ë ¹ì–´ê°€ ì €ì¥ëœ í† í° ì •ë³´ ìš°ì„  ì‚¬ìš©

### Estimation ì‚¬ìš© ìµœì†Œí™”
- âœ… Assistant ë©”ì‹œì§€: API ì‹¤ì œ í† í° ì‚¬ìš©
- âš ï¸ User ë©”ì‹œì§€: Estimation ì‚¬ìš© (4 chars = 1 token)
- âš ï¸ ì²˜ìŒ ì‹œì‘ ì‹œ: Estimation ì‚¬ìš©
- âœ… ëŒ€í™” ì§„í–‰ í›„: ëŒ€ë¶€ë¶„ ì‹¤ì œ í† í° ì‚¬ìš©

---

## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### Scenario 1: ì»¨í…ìŠ¤íŠ¸ í™•ì¸
```
You: /context
 Context Usage
 â› â› â› â›€ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   openai/gpt-oss-120b Â· 42.7k/65.5k tokens (65.1%)

â†’ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©ëŸ‰ì´ 65%ì…ë‹ˆë‹¤. ì—¬ìœ ê°€ ìˆìŠµë‹ˆë‹¤.
```

### Scenario 2: ì»¨í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•  ë•Œ
```
You: /context
 Context Usage
 â› â› â› â› â› â› â› â› â› â›   openai/gpt-oss-120b Â· 78.8k/65.5k tokens (120.3%)
 â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   â›¶ Free space: -13.3k (-20.3%) âš ï¸  OVER LIMIT!

â†’ ì»¨í…ìŠ¤íŠ¸ í•œê³„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!

You: /compact
âœ… Conversation compacted. Kept 7 messages.

You: /context
 Context Usage
 â› â› â› â›€ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   openai/gpt-oss-120b Â· 33.2k/65.5k tokens (50.7%)

â†’ ì••ì¶• í›„ 50%ë¡œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤!
```

### Scenario 3: ìƒˆë¡œìš´ ì£¼ì œë¡œ ì „í™˜
```
You: /clear
âœ… Conversation history cleared.

You: /context
 Context Usage
 â› â› â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶ â›¶   openai/gpt-oss-120b Â· 13.2k/65.5k tokens (20.2%)

â†’ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì£¼ì œë¡œ ì‹œì‘!
```

### Scenario 4: ë””ë²„ê¹…
```
You: /context debug
=== DEBUG INFO ===
  llm_client.last_input_tokens: 26,666
  message_stats:
    total_messages: 10
    with_actual_tokens: 8      â† 80%ëŠ” ì‹¤ì œ í† í°
    with_estimated_tokens: 2   â† 20%ëŠ” ì¶”ì •

â†’ ëŒ€ë¶€ë¶„ì˜ ë©”ì‹œì§€ê°€ ì‹¤ì œ API í† í°ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤!
```

---

## êµ¬í˜„ íŒŒì¼

### ìˆ˜ì •ëœ íŒŒì¼
1. **`brian_coder/core/context_tracker.py`**
   - Context tracking ëª¨ë“ˆ
   - í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚° ë° ì‹œê°í™”
   - ì €ì¥ëœ í† í° ë©”íƒ€ë°ì´í„° ìš°ì„  ì‚¬ìš©

2. **`brian_coder/core/slash_commands.py`**
   - `/context`, `/clear`, `/compact` ëª…ë ¹ì–´
   - ë””ë²„ê·¸ ëª¨ë“œ ì¶”ê°€

3. **`brian_coder/src/main.py`**
   - `/clear`, `/compact` í•¸ë“¤ë§ ê°œì„ 
   - context_tracker ìë™ ì—…ë°ì´íŠ¸
   - conversation_history ìë™ ì €ì¥

4. **`brian_coder/src/llm_client.py`**
   - `get_last_usage()` í•¨ìˆ˜ ì¶”ê°€
   - `last_output_tokens` ì¶”ì 
   - í† í° ë©”íƒ€ë°ì´í„° ìë™ ì €ì¥

---

## í…ŒìŠ¤íŠ¸ ê²°ê³¼

### âœ… /context
- API ì‹¤ì œ í† í°ê³¼ 100% ì¼ì¹˜
- ì €ì¥ëœ ë©”íƒ€ë°ì´í„° ì •ìƒ ì‚¬ìš©
- Estimation ìµœì†Œí™”

### âœ… /clear
- ëŒ€í™” ê¸°ë¡ ì™„ì „ ì´ˆê¸°í™”
- context_tracker ì˜¬ë°”ë¥´ê²Œ ì—…ë°ì´íŠ¸
- conversation_history.json ì €ì¥ í™•ì¸

### âœ… /compact
- ì˜¤ë˜ëœ ë©”ì‹œì§€ ìš”ì•½
- ìµœê·¼ 5ê°œ ë©”ì‹œì§€ ìœ ì§€
- í† í° ì‚¬ìš©ëŸ‰ 60-70% ì ˆê°

---

## ê²°ë¡ 

Brian Coderì— Claude Code ìˆ˜ì¤€ì˜ context management ê¸°ëŠ¥ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤:

1. **ì •í™•í•œ í† í° ì¶”ì ** - API ì‹¤ì œ ê°’ ì‚¬ìš©, estimation ìµœì†Œí™”
2. **ì‹œê°ì  í‘œì‹œ** - Claude Code ìŠ¤íƒ€ì¼ progress bar
3. **íš¨ìœ¨ì ì¸ ê´€ë¦¬** - /clear, /compactë¡œ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
4. **ìë™ ì €ì¥** - í† í° ì •ë³´ê°€ íˆìŠ¤í† ë¦¬ì— ì €ì¥ë˜ì–´ ì„¸ì…˜ ê°„ ìœ ì§€

ì‚¬ìš©ìëŠ” ì´ì œ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©ëŸ‰ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³ , í•„ìš”ì— ë”°ë¼ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ì••ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€
