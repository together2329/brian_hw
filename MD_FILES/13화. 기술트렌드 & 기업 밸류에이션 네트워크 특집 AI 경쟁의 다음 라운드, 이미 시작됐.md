---
title: "어스플러스"
source: "https://us-insight.com/secrets/15260"
author:
published:
created: 2025-12-28
description: "개인 투자자를 위한 최고의 실전투자 교육 플랫폼. 리딩방 사칭방 걱정없는 전문가들의 올바른 투자 콘텐츠를 제공합니다."
tags:
  - "clippings"
---
![어스플러스](https://us-insight.com/_next/image?url=%2Fheader%2FLogo.png&w=256&q=75)

My 멤버십

월텍남의 실전투자클럽

멤버십

13화. \[기술트렌드 & 기업 밸류에이션\]네트워크 특집: AI 경쟁의 다음 라운드, 이미 시작됐다?

월텍남의 실전투자클럽

약 12시간 전

38

**네트워크 특집**

**AI 투자 지형의 대전환: GPU를 넘어 네트워크로**

---

![](https://contents-resource.us-insight.com/dev/image/png/338e2703/1766829035200_338e2703__1.79649__OwgGBIDGrImJL5W1eWPC0AwO3w?w=1080)

## 서론: 새로운 AI 전쟁의 서막

인공지능(AI) 개발 경쟁이 새로운 국면에 접어들었습니다. 초기 AI 시장이 더 많은 그래픽 처리 장치(GPU)를 확보하는 순수한 연산 능력(Computational Power) 경쟁이었다면, 이제는 한정된 자원을 얼마나 효율적으로 활용하여 투자 수익률(ROI)을 극대화하느냐는 정교한 효율성 경쟁으로 진화하고 있습니다. 이는 단순한 규모의 확장을 넘어, 질적 성장을 추구하는 전략적 전환을 의미합니다.

본 보고서는 **AI 투자 패러다임의 대전환** 을 심층적으로 분석하고, 이 변화의 중심에 있는 **네트워크 인프라의 결정적 역할** 을 조명하고자 합니다.

나아가, GPU를 넘어 네트워크로 향하는 **새로운 투자 물결의 핵심 수혜 기업들을 식별** 하여 투자자들에게 명확한 방향을 제시할 것입니다. AI 주도권 경쟁의 무대가 어떻게 변화하고 있는지, 그 흐름을 따라가 보겠습니다.

읽기 전 먼저 양해를 구합니다. 글이 다소 어렵습니다(ㅠㅠ) 통신을 다루다 보니, 컴퓨터공학과 전자공학을 넘나듭니다. 최대한 읽기 좋게 부연 설명을 넣어두었음에도, 다소 어려울 것이라는 점 죄송합니다.

**==사전 배경지식: What’s in my Datacenter?==**

이번 시간에 다룰 부분은 데이터 센터 중 4. 네트워크 부분입니다.

![](https://contents-resource.us-insight.com/dev/image/png/890fe4a6/1766829040462_890fe4a6__1.45278__M/gJBYL2iHl3iIeLdye3jPeTV2/X?w=1080)

**\[데이터센터 구성요소 4가지\]**

데이터센터는 크게 4가지 핵심 인프라로 구성됩니다.

1. **컴퓨팅(Compute):** CPU, GPU 등 연산을 담당하는 서버
2. **스토리지(Storage):** 데이터를 저장하는 SSD, HDD 등 저장 장치
3. **전력/쿨링(Power & Cooling):** 장비에 전력을 공급하고 열을 식히는 시스템
4. ***==네트워크(Network)==: 서버, 스토리지, 외부 세계를 연결하는 '혈관' ← 이번 주제***

**\[네트워크가 왜 중요한가?\]**

AI 학습은 수천 개의 GPU가 동시에 데이터를 주고받으며 협업하는 과정입니다. 아무리 빠른 GPU를 갖춰도, 데이터를 전달하는 네트워크가 느리면 GPU는 '대기' 상태로 놀게 됩니다. 비유하자면:

- **GPU** = 공장의 기계
- **네트워크** = 공장 내 컨베이어 벨트

컨베이어 벨트가 막히면 아무리 좋은 기계도 제 속도를 낼 수 없듯, 네트워크 병목은 전체 AI 시스템의 효율을 떨어뜨립니다.

**\[핵심 네트워크 지표 3가지\]**

- **대역폭(Bandwidth):** 한 번에 얼마나 많은 데이터를 보낼 수 있는가 (도로 차선 수)
- **지연시간(Latency):** 데이터가 목적지까지 도달하는 데 걸리는 시간 (통행 속도)
- **처리량(Throughput):** 실제로 단위 시간당 전송되는 데이터양 (실제 교통량)

![](https://contents-resource.us-insight.com/dev/image/png/fb312cda/1766829062078_fb312cda__1.83184__9PcFBID2VsZ6pF2arHyvZZzPiA?w=1080)

**\[네트워크 핵심 하드웨어 5가지\]**

1. **스위치(Switch):** 데이터의 '교통 정리'. 어느 서버로 데이터를 보낼지 결정하고 전달합니다.
	- *스파인 스위치:* 데이터센터의 '척추', 모든 트래픽이 지나가는 고속도로
	- *리프 스위치:* 서버와 직접 연결되는 말단 스위치
2. **NIC(네트워크 인터페이스 카드):** 서버를 네트워크에 연결하는 카드입니다. 최신 AI 서버는 고성능 NIC를 통해 CPU 부하를 줄입니다.
3. **광 트랜시버(Optical Transceiver):** 전기 신호↔광 신호 변환기. 빛으로 데이터를 전송해 장거리 고속 통신을 가능하게 합니다.
4. **케이블(Cable):** 데이터가 실제로 이동하는 '도로'
	- *광케이블:* 빛으로 전송, 장거리·고속도에 유리
	- *구리 케이블(DAC):* 전기로 전송, 단거리·저비용에 유리
5. **커넥터(Connector):** 케이블과 장비를 연결하는 '플러그'. 고속 통신에서는 신호 손실을 최소화하는 정밀 기술이 필요합니다.

---

## 제1부: AI 투자의 패러다임 변화 - 규모에서 효율로

### 1.1. 멈추지 않는 AI 투자, 그러나 고민은 깊어진다

![](https://contents-resource.us-insight.com/dev/image/png/014ca671/1766829089285_014ca671__1.77778__+fcFDIL4yIeZe3F5WmWgqwmpeg?w=1080)

주요 하이퍼스케일러들의 설비투자(Capex)는 연일 사상 최고치를 경신하며 AI에 대한 강력한 투자 의지를 보여주고 있습니다.

그러나 이면에서는 **==급증하는 비용 부담==** 과 그에 따른 잉여현금흐름(FCF) 감소, 자기자본이익률(ROE)에 대한 우려가 깊어지면서 전략적 전환을 강요하고 있습니다.

이 거대한 투자는 2025년 3,462억 달러(+52% YoY), **2026년 4,021억 달러, 2027년에는 4,343억 달러** 까지 확대될 전망으로, AI가 클라우드 이후 가장 큰 기술적 변곡점임을 증명하고 있습니다.

이러한 공격적인 지출은 재무제표에 즉각적인 압박으로 나타납니다 Capex가 급증하는 동안 주요 하이퍼스케일러들의 잉여현금흐름(FCF)은 감소 압력을 받고 자기자본이익률(ROE)은 정체되는 모습을 보여, **투자 효율성에 대한 근본적인 의문이 제기되고 있습니다.**

**결국 핵심은 “AI로 돈 버냐?”라는 질문으로 귀결됩니다.**

**\[재무 용어 정리\]**

- **FCF (Free Cash Flow):** 잉여현금흐름. 영업활동으로 번 돈에서 Capex를 뺀, 회사가 자유롭게 쓸 수 있는 현금입니다. 배당, 인수합병 등에 활용됩니다.
- **ROE (Return on Equity):** 자기자본이익률. 주주가 투자한 돈 대비 얼마나 이익을 냈는지 보여주는 지표로, 기업의 효율성을 판단하는 핵심 척도입니다.
- **TCO (Total Cost of Ownership):** 총소유비용. 장비 구매 비용뿐 아니라 **운영, 유지보수, 전력, 냉각 등 전체 수명 주기** 에 드는 모든 비용을 합산한 것입니다.
- **OpEx (Operating Expenses):** 운영비. 전기료, 인건비, 임대료 등 일상적인 사업 운영에 드는 비용입니다. cf) Capex

- **==급격한 Capex 증가율==:** 최근 2년간 50%를 상회하는 폭발적인 증가율을 감안할 때, 향후 증가율 둔화는 불가피합니다.
- **==재무적 부담==:** 전례 없는 Capex 확대는 FCF 감소로 이어지고 있으며, 투자 수익률에 대한 시장의 우려 또한 상존합니다.
- **==전략의 변화==:** 이제 투자의 무게중심은 단순한 규모 확대에서 벗어나 Capex, 총소유비용(TCO), 운영비(OpEx)를 종합적으로 고려하는 '투자 효율성' 극대화로 이동하고 있습니다.

이러한 변화에 따라, 향후 AI 투자는 단순히 더 많은 GPU를 확보하는 데 그치지 않을 것입니다. Google의 TPU, Amazon의 Trainium과 같은 자체 AI 가속기 개발을 통한 풀스택(Full-stack) 전략이 확산되는 것과 마찬가지로, **이제 투자의 초점은 TCO와 OpEx를 고려하여 이미 확보한 GPU 자산의 운영 효율성을 어떻게 극대화할 것인지에 맞춰질 것입니다.**

**그 해답은 바로 시스템의 혈관, 네트워크에 있습니다.**

---

**1.2. 네트워크: AI ROI를 극대화할 최적의 해법**

![](https://contents-resource.us-insight.com/dev/image/png/c26a541c/1766829145928_c26a541c__1.77778__OggGDID5WHdleoiFiGbWwj8e/Q?w=1080)

네트워크 인프라는 더 이상 AI 시스템의 보조적인 지원 역할에 머무르지 않습니다. 오히려 고가의 GPU 자산 가치를 온전히 끌어내고 AI 투자 수익률을 극대화하기 위한 핵심적인 전략 자산으로 부상하고 있습니다.

***AI 데이터센터 Capex에서 네트워크가 차지하는 비중은 10% 미만에 불과하지만, AI 학습 과정에서 발생하는 ==대기 시간의 최대 30%가 네트워크 응답 지연 때문에 발생== 합니다.***

*참고로 데이터센터 운영비용에서는 쿨링이 40%, 서버 39%, 네트워크 10%를 차지합니다.*

![](https://contents-resource.us-insight.com/dev/image/png/78b06e90/1766829151165_78b06e90__1.09363__NPgFDoL42mR4dod3OnNHqkeCYIWz/Zc?w=1080)

***이는 비교적 적은 비용을 네트워크에 투자하는 것만으로도 전체 시스템의 효율성을 극적으로 개선할 수 있는 강력한 레버리지 포인트가 존재함을 시사합니다.***

Nvidia 역시 최근 2Q25 실적 발표에서 올바른 네트워킹 기술이 "성능 향상 → 처리량 개선 → 비용 절감 → 투자 효율 극대화"로 이어지는 선순환을 가능하게 한다고 강조하며 이러한 흐름을 뒷받침했습니다. 실제로 Nvidia의 네트워킹 사업부는 데이터센터 매출 내 비중이 18%(+5%p QoQ)까지 확대되며 사상 최대 매출을 기록, 시장의 무게중심이 이동하고 있음을 증명했습니다.

이러한 추세에 힘입어 데이터센터 네트워크 시장은 **2023년부터 2030년까지 연평균 15%의 견조한 성장** 을 이어갈 것으로 전망됩니다.

**그중에서도, AI 관련된 네트워킹 마켓은 ==연간 33% 성장하는 초고성장 시장== 입니다.**

![](https://contents-resource.us-insight.com/dev/image/png/441eb12e/1766829163552_441eb12e__1.72101__thcKHIZpeIdviHhSiIh6f2UHyA?w=1080)

> 많은 사람들이 AI의 핵심을 GPU라고 생각하지만, 이건 70%만 맞는 말입니다. 최고급 스포츠카(GPU)를 여러 대 사놓고 비포장도로(네트워크)에서 달리게 하는 셈이죠. 하이퍼스케일러들은 이제 이 '도로'를 고속도로로 바꾸는 작업에 돈을 쓰기 시작한 겁니다. 적은 비용으로 전체 시스템의 효율을 몇 단계나 끌어올릴 수 있는 '가성비' 최고의 투자인 셈이죠. **앞으로 AI 기업의 경쟁력은 보유한 GPU의 수 뿐만 아니라, 네트워킹 기술로 GPU를 얼마나 쉬지 않고 일하게 만드느냐** 에 따라 결정될 겁니다.

---

## 제2부: AI 시대의 네트워크 기술 완벽 가이드

### 2.1. 데이터센터의 기본 구조: 스파인-리프 아키텍처

![](https://contents-resource.us-insight.com/dev/image/png/453aee38/1766829186543_453aee38__1.77778__+PcFDIL3t2qGeYiZV2XoeY+e9w?w=1080)

현대 데이터센터의 성능은 네트워크의 물리적, 논리적 설계에 의해 크게 좌우됩니다. 특히 AI 워크로드에서 발생하는 방대하고 병렬적인 데이터 흐름을 효율적으로 처리하기 위해서는 최적화된 네트워크 아키텍처가 필수적입니다.

오늘날 데이터센터 네트워크의 표준으로 자리 잡은 **'스파인-리프(Spine-Leaf)'** 아키텍처는 과거 3계층 구조의 한계를 극복하기 위해 설계되었습니다. 3계층 구조는 상위 계층으로 갈수록 트래픽이 집중되어 병목 현상이 발생하기 쉬웠지만, 스파인-리프 구조는 이를 2계층으로 단순화하고 모든 경로를 최적화하여 데이터 흐름의 효율성을 극대화합니다.

\[NOTE\] **개념 설명: 스파인-리프(Spine-Leaf) 구조란?**

![](https://contents-resource.us-insight.com/dev/image/png/410e76b2/1766829193688_410e76b2__1.77778__PQgGBICIuXeId3h/Z3aRlhBpCQ?w=1080)

이 구조를 구성하는 주요 요소들의 역할은 다음과 같습니다.

- **리프(Leaf) 스위치:** 서버 랙에 배치되어 서버와 직접 연결됩니다. 일반적으로 한 대의 스위치에 20~48대의 서버를 연결하며, AI 서버 환경에서는 네트워크 이중화를 위해 랙당 2대 이상을 두기도 합니다. 각 서버에서 발생한 데이터를 모아 상위의 스파인 스위치로 전달하는 역할을 합니다.
- **스파인(Spine) 스위치:** 데이터센터의 '척추'와 같은 역할을 합니다. 모든 리프 스위치를 서로 연결하는 고속도로로서, AI 데이터센터에서는 일반적으로 400Gbps 이상의 고속 포트를 갖추며, 트래픽 분산을 위해 수십 개까지 배치되기도 합니다. 대규모 트래픽을 지연 없이 처리하는 초고속, 저지연 기술이 핵심입니다.
- **기타 조연들:** 서버와 스위치를 잇는 네트워크 카드(NIC), 전기 신호와 광 신호를 상호 변환하는 광 트랜시버, 그리고 빛의 형태로 데이터를 전송하는 광케이블 등이 이 구조를 완성하는 필수 부품들입니다.

이러한 물리적 구조 위에서 데이터를 효율적으로 주고받기 위해 다양한 통신 기술들이 경쟁하고 있습니다.

---

### 2.2. 서버 간의 통신 기술: 인피니밴드 vs 이더넷

![](https://contents-resource.us-insight.com/dev/image/png/8173a687/1766829246295_8173a687__1.77778__+gcGDIKn+vqGiYZ8eGcNWrSQNg?w=1080)

AI 데이터센터 내 서버 간 통신 기술 시장은 고성능을 추구하는 독점 기술과 범용성을 앞세운 개방형 표준 기술 간의 전략적 경쟁이 치열하게 벌어지는 장입니다.

**\[통신 기술 용어 정리\]**

- **HPC (High Performance Computing):** 고성능컴퓨팅. 슈퍼컴퓨터나 수천 대의 서버를 병렬로 연결해 일반 컴퓨터로는 불가능한 복잡한 계산을 수행하는 기술입니다.
- **RDMA (Remote Direct Memory Access):** 원격 직접 메모리 접근. CPU를 거치지 않고 한 컴퓨터의 메모리에서 다른 컴퓨터의 메모리로 데이터를 직접 전송하는 기술입니다. 마치 택배가 중간 물류센터(CPU)를 거치지 않고 문 앞에서 문 앞으로 직접 배송되는 것과 같습니다.
	**→ 엔비디아 네트워킹 우위의 기반이 된 아주 중요한 개념입니다.**
- **TCP/IP:** 인터넷의 기본 통신 프로토콜. 데이터를 작은 패킷으로 쪼개 전송하고 도착지에서 재조립하는 방식으로, 범용성이 높지만 CPU가 관여해야 해서 지연이 발생합니다.
- **Vendor Lock-in:** 특정 공급업체의 제품/서비스에 종속되어 다른 업체로 전환하기 어려운 상태. 전환 비용이 높아 협상력이 약해지는 단점이 있습니다.

<table><colgroup><col> <col> <col></colgroup><tbody><tr><td colspan="1" rowspan="1"><p><strong>구분</strong></p></td><td colspan="1" rowspan="1"><p><span><strong>인피니밴드 (InfiniBand)</strong></span></p></td><td colspan="1" rowspan="1"><p><span><strong>이더넷 (Ethernet)</strong></span></p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>핵심 철학</strong></p></td><td colspan="1" rowspan="1"><p>초저지연, 고대역폭을 위한 고성능컴퓨팅(HPC) 전용 기술</p></td><td colspan="1" rowspan="1"><p>범용성, 호환성, 비용 효율성을 중시하는 표준 기술</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>성능</strong></p></td><td colspan="1" rowspan="1"><p>GPU 간 병렬 연산에 최적화된 최고 성능</p></td><td colspan="1" rowspan="1"><p>CPU 개입으로 인한 지연 시간 발생 가능성</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>핵심 기술</strong></p></td><td colspan="1" rowspan="1"><p>RDMA: CPU를 거치지 않고 메모리 간 직접 데이터 전송</p></td><td colspan="1" rowspan="1"><p>TCP/IP: CPU가 데이터 패킷화 및 전송에 깊이 관여</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>생태계</strong></p></td><td colspan="1" rowspan="1"><p><span><strong>Nvidia(Mellanox) 중심의 폐쇄적, 독점적 구조</strong></span></p></td><td colspan="1" rowspan="1"><p><span><strong>개방형 표준</strong> 으로 다양한 업체 참여, 호환성 높음</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>비용</strong></p></td><td colspan="1" rowspan="1"><p>고가</p></td><td colspan="1" rowspan="1"><p>상대적으로 저렴</p></td></tr></tbody></table>

이러한 구도에 도전장을 내민 것이 바로 **RoCE (RDMA over Converged Ethernet)** 기술입니다. RoCE는 이더넷 진영이 인피니밴드의 성능 우위에 대응하기 위해 내놓은 해법으로, 이더넷의 비용 효율성과 인프라 호환성 위에 인피니밴드의 핵심 기술인 RDMA의 성능을 결합한 것입니다.

\[NOTE\] **개념 설명: RoCE란 무엇인가?**

![](https://contents-resource.us-insight.com/dev/image/png/d4ddcefb/1766829285805_d4ddcefb__2.54341__M/gFC4J5qJlsiPZ3iV912Ag?w=1080)

왼쪽의 TCP는 수많은 계측을 거쳐서 전송이 됩니다. 반면에 오른쪽의 ROCE구조는 바로 직결로 연결이 됩니다.**(그림의 빨간색 화살표 방향 참조)**

- RoCE (RDMA over Converged Ethernet)는 표준 이더넷 네트워크 위에서 **RDMA** 기술을 구현할 수 있게 해주는 네트워크 프로토콜입니다.
- **RDMA란?** 네트워크상의 컴퓨터들이 데이터를 주고받을 때, 서로의 **CPU나 운영체제를 거치지 않고 메모리 대 메모리로 직접 데이터를 전송** 하는 기술로, 기존의 복잡한 TCP/IP 스택을 건너뛰고 하드웨어 차원에서 데이터를 처리합니다.
- **주요 장점:**
	**1) 낮은 지연 시간(Low Latency):** 데이터 처리 경로가 짧아져 통신 속도가 획기적으로 빠릅니다.
	**2) 낮은 CPU 부하:** 네트워크 전송 업무를 CPU가 아닌 네트워크 카드(NIC)가 대신 처리하므로, CPU는 다른 계산 작업에 집중할 수 있습니다.
	**3) 높은 효율성:** 기존 이더넷 인프라를 그대로 활용하면서도 인피니밴드(InfiniBand)와 유사한 고성능을 낼 수 있습니다.

시장에서는 이미 변화의 조짐이 나타나고 있습니다. 2024년까지 AI 백엔드 네트워크 시장의 80% 이상을 점유하며 독주하던 인피니밴드에 맞서, Meta, Microsoft와 같은 하이퍼스케일러들이 이더넷/RoCE 진영에 힘을 싣고 있습니다. 특정 공급업체에 대한 종속(Vendor Lock-in)을 피하고 TCO를 최적화하려는 이들의 움직임이 이더넷 생태계의 성장을 가속화하고 있습니다.

> **이 싸움은 단순히 '기술'의 대결이 아니라 '철학'의 대결입니다.** Nvidia는 '최고의 성능을 원하면 우리 생태계 안으로 들어오라'는 폐쇄적인 전략을, 이더넷 진영은 '누구나 함께 만들어가는 개방적인 생태계'를 추구하죠. 단기적으로는 Nvidia가 앞서가지만, 장기적으로는 비용과 선택의 자유를 중시하는 고객사들이 이더넷 진영에 힘을 실어줄 가능성이 높습니다. Arista 등이 주도하는 UEC(Ultra Ethernet Consortium)에 업계 거물들이 참여하며 개방형 생태계를 구축하려는 움직임이 그 명백한 증거입니다.

서버 간 통신을 넘어, 이제 경쟁은 AI 연산의 최소 단위인 **GPU 간 직접 통신 기술** 로까지 확산되고 있습니다.

### 2.3. GPU 간의 직접 통신: NVLink vs UALink

![](https://contents-resource.us-insight.com/dev/image/png/de874738/1766829329005_de874738__1.77778__OQgGBIC2/WqZSna+OkAbZO9h9Q?w=1080)

대규모 AI 모델 학습의 효율성은 수많은 GPU가 얼마나 빠르고 직접적으로 데이터를 교환할 수 있느냐에 따라 결정됩니다. 이를 위해 GPU 간 직접 통신을 위한 고속 인터커넥트 기술이 핵심적인 역할을 합니다.

**\[GPU 연결 기술 용어 정리\]**

- **PCIe (Peripheral Component Interconnect Express):** 컴퓨터 내부에서 CPU, GPU, SSD 등 각종 부품을 연결하는 범용 고속 통로입니다. USB가 외부 기기 연결용이라면, PCIe는 내부 부품 연결용이라고 보면 됩니다.
![](https://contents-resource.us-insight.com/dev/image/png/85c73ed9/1766829341246_85c73ed9__1.77941__mUgGHIhxuo1veneTa0uJZz/V+g?w=1080)
- **NVLink:** Nvidia가 개발한 GPU 전용 초고속 연결 기술. PCIe보다 훨씬 빠른 속도로 여러 GPU가 마치 하나의 거대한 GPU처럼 작동하게 해줍니다.
![](https://contents-resource.us-insight.com/dev/image/png/1252464d/1766829346004_1252464d__1.77596__UfgFFIAIepSJd3lhm2YYadD9kg?w=1080)
- **UALink (Ultra Accelerator Link):** Nvidia 독점에 대항해 AMD, Google, Microsoft 등이 만든 개방형 GPU 연결 표준입니다.
- **인터커넥트 (Interconnect):** 칩, 서버, 장비 간의 고속 연결 통로를 총칭하는 말입니다. 고속도로에 비유할 수 있습니다.

Nvidia의 **NVLink** 는 범용 통신 표준인 PCIe의 병목 현상을 극복하기 위해 개발된 독점적인 고성능 GPU-to-GPU 통신 기술입니다. NVLink는 NVLink Switch를 통해 최대 576개의 GPU를 하나의 거대한 가속기처럼 연결하여, 데이터 전송 지연을 최소화하고 AI 학습 성능을 극대화합니다.

이에 대항하여 AMD, Google, Microsoft 등이 주축이 된 컨소시엄은 개방형 표준 기술인 UALink (Ultra Accelerator Link)를 발표했습니다. UALink는 Nvidia의 독점적 생태계에 도전하는 가장 강력한 대안으로 부상하고 있습니다.

<table><colgroup><col> <col> <col> <col></colgroup><tbody><tr><td colspan="1" rowspan="1"><p><strong>기술</strong></p></td><td colspan="1" rowspan="1"><p><strong>레인당 속도</strong></p></td><td colspan="1" rowspan="1"><p><strong>확장성 (연결 가능 장치)</strong></p></td><td colspan="1" rowspan="1"><p><strong>생태계</strong></p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>PCIe 5.0</strong></span></p></td><td colspan="1" rowspan="1"><p>8 GB/s</p></td><td colspan="1" rowspan="1"><p>약 100여 개</p></td><td colspan="1" rowspan="1"><p>범용 (모든 장치 호환)</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>NVLink 5.0</strong></span></p></td><td colspan="1" rowspan="1"><p>100 GB/s</p></td><td colspan="1" rowspan="1"><p>576개 (GPU)</p></td><td colspan="1" rowspan="1"><p>폐쇄형 (Nvidia 전용)</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>UALink</strong></span></p></td><td colspan="1" rowspan="1"><p>25 GB/s</p></td><td colspan="1" rowspan="1"><p>1,024개 (가속기)</p></td><td colspan="1" rowspan="1"><p>개방형</p></td></tr></tbody></table>

UALink의 진정한 경쟁력은 단순한 속도를 넘어, 특정 공급업체에 종속되지 않는 '개방성', NVLink를 뛰어넘는 '확장성'(최대 1,024개 가속기 연결), 그리고 잠재적인 '비용 효율성'에 있습니다. 이는 Nvidia의 하드웨어 종속 전략에 정면으로 도전하는 것으로, 2026년 AMD의 MI400 시리즈를 시작으로 본격적인 상용화가 예상됩니다.

![](https://contents-resource.us-insight.com/dev/image/png/e5f8560c/1766829412107_e5f8560c__1.78082__hfcFDIIpJriHeHhgq4jLas/+5A?w=1080)

---

### UALink, 과연 성공할 수 있을까? — 비판적 분석

UALink의 비전은 명확합니다. Nvidia 독점을 깨고 개방형 생태계를 만들겠다는 것. 그러나 현실은 다릅니다. **UALink가 넘어야 할 산은 예상보다 훨씬 높습니다.**

**1\. 압도적인 성능 격차**

UALink의 레인당 속도는 25GB/s입니다. NVLink 5.0은 100GB/s. **4배 차이** 입니다. 확장성에서 1,024개 vs 576개로 우위를 주장하지만, AI 학습에서 중요한 건 연결 수가 아니라 **실제 대역폭** 입니다. 더 많은 GPU를 연결해도 파이프가 좋으면 무슨 소용이겠습니까? 레인당 속도가 못해도 NVLink의 70% 이상은 되어야 비벼볼만할 것 같습니다.

**2\. 시간과의 싸움에서 이미 뒤처졌다?**

NVLink는 2014년부터 시작되어 10년 이상 고도화되었습니다. UALink 1.0은 2025년 4월에야 정식 발표됐습니다. 첫 상용 제품은 2026년 AMD MI400 시리즈에서 나올 예정입니다. 그때쯤이면 Nvidia는 이미 Rubin 플랫폼과 함께 더 진화한 NVLink를 내놓을 겁니다. **따라가는 순간 또 멀어지는 구조입니다.**

**3\. CUDA 생태계라는 거대한 해자**

NVLink의 진짜 경쟁력은 하드웨어가 아닙니다. **CUDA + NVLink + NIM** 으로 엮어진 소프트웨어 생태계입니다. 개발자들이 10년간 CUDA로 코드를 짰습니다. UALink는 하드웨어 연결 표준일 뿐, 이 소프트웨어 장벽을 넘을 방법이 없습니다.

**4\. 컨소시엄의 태생적 한계**

UALink 컨소시엄에는 AMD, Intel, Google, Microsoft, Meta 등이 참여합니다. 문제는 이들의 이해관계가 일치하지 않는다는 점입니다.

- **AMD**: 자사 GPU를 팔아야 합니다
- **Intel**: 가속기 시장에서 고전 중입니다
- **Google/AWS**: 자체 칩(TPU, Trainium)을 밀어야 합니다
- **Microsoft/Meta**: Nvidia와도 계속 거래해야 합니다

**"공동의 적"을 만들었지만, 각자 싸울 전선이 다릅니다.** USB나 PCIe처럼 모두가 이득을 보는 범용 표준과는 상황이 다릅니다.

**5\. "개방형"이라는 역설**

"개방형 생태계"라는 말은 듣기 좋습니다. 하지만 개방형이 항상 승리하는 건 아닙니다. Betamax vs VHS, HD-DVD vs Blu-ray, Thunderbolt vs USB-C… 기술 표준 전쟁에서 "더 좋은 기술"이 진 경우는 얼마든지 있습니다. **시장 타이밍, 생태계 락인, 고객 관성** 이 더 중요합니다.

**==핵심 질문: UALink이 성공하려면?==**

1. NVLink와 대등한 성능을 입증해야 합니다 (현재 4배 격차)
2. CUDA 대안 소프트웨어 스택이 필요합니다 (ROCm? 부족합니다)
3. 대규모 클러스터에서 실제 성공 사례가 나와야 합니다 (2026년 이후)
4. 컨소시엄 내부 분열 없이 로드맵을 지켜야 합니다.

> 경쟁자들이 뛰어드는 건 좋은 일입니다. 하지만 박수 치기엔 이릅니다. UALink은 Nvidia에게 '협상 레버리지'를 제공할 수 있지만, 아직은 많이 일러 보입니다.

---

## 제3부: AI 네트워크 혁명의 수혜 기업 분석

### 3.1. 대역폭 경쟁의 최전선: 400G → 800G → 1.6T

![](https://contents-resource.us-insight.com/dev/image/png/79fbe3b5/1766829525572_79fbe3b5__1.77778__+fcFDIC7h/Wdd3VWiWYPd+xgpw?w=1080)

데이터센터 네트워크의 속도 경쟁은 단순한 성능 향상을 넘어, Nvidia의 Blackwell이나 AMD의 MI400과 같은 차세대 AI 가속기의 잠재력을 최대한 끌어내기 위한 필수적인 진화 과정입니다.

**\[네트워크 인프라 용어 정리\]**

- **400G / 800G / 1.6T:** 네트워크 속도를 나타내는 단위. 400G는 초당 400기가비트, 즉 50GB의 데이터를 전송할 수 있는 속도입니다. 4K 영화 1편(약 100GB)을 2초 만에 전송할 수 있는 수준
- **ASIC (Application-Specific Integrated Circuit):** 주문형 반도체. 특정 용도(예: 네트워크 스위칭)에 최적화되어 설계된 칩으로, 범용 칩보다 해당 작업에서 훨씬 빠르고 전력 효율이 좋음
- **CPO (Co-packaged Optics):** 광학 부품을 스위치 칩과 같은 패키지 안에 통합하는 첨단 기술입니다. 데이터 전송 거리가 짧아져 전력 소모와 지연을 크게 줄일 수 있음
- **광 트랜시버 (Optical Transceiver):** 전기 신호를 빛(광 신호)으로, 빛을 다시 전기 신호로 변환하는 부품입니다. 장거리 고속 데이터 전송의 핵심 부품
- **ODM (Original Design Manufacturer):** 제조자 개발 생산. 고객사의 요구에 맞춰 제품을 설계하고 생산해주는 업체입니다. 파트너사 브랜드로 판매됨
- **White Box:** 브랜드 없이 범용 하드웨어로 만든 네트워크 장비. 하이퍼스케일러들이 비용 절감과 맞춤화를 위해 직접 설계하고 ODM에 생산을 맡기는 방식.

- **과거 (2019~2023):** 400G가 클라우드 및 AI 데이터센터의 표준으로 자리 잡았습니다.
- **현재 (2024~2025):*****생 성형 AI 수요가 폭증하면서 800G로의 전환*** 이 '선택이 아닌 필수'가 되었습니다. Celestica, Viavi 등 주요 네트워크 관련 기업들은 시장의 예상을 뛰어넘는 강력한 800G 전환 수요를 확인하며 긍정적인 전망을 제시하고 있습니다.
	![](https://contents-resource.us-insight.com/dev/image/png/fd6c16f2/1766829564819_fd6c16f2__1.79021__tugJPITMh5d4dngslnCwlmCfmA?w=1080)
- **미래 (2026~):** 1.6Tbps 시대의 서막이 열릴 것입니다. Nvidia는 2026년 출시될 Rubin 플랫폼에 1.6T 스위치를, 2028년 Feynman 플랫폼에는 3.2T 스위치를 요구할 것으로 전망되며, 기술 로드맵을 선도하고 있습니다.

800G로의 업그레이드는 속도를 두 배로 높이는 것 이상의 다각적인 이점을 제공합니다.

- **전력 효율성:** 동일한 양의 데이터를 전송할 때 비트당 전력 소모가 감소하여 에너지 효율성이 개선됩니다.
- **비용 효율성:** 400G 포트 2개를 사용하는 것보다 800G 포트 1개를 사용하는 것이 더 비용 효율적입니다.
- **공간 효율성 및 확장성:** 더 적은 물리적 공간에서 더 많은 서버를 연결하거나, 링크를 유연하게 분리하여 활용할 수 있습니다.
![](https://contents-resource.us-insight.com/dev/image/png/42d0e30f/1766829571465_42d0e30f__1.77778__PPgFBID4OHdyi3Z5hnj4dXx/uA?w=1080)

이러한 속도 경쟁은 스위치라는 단일 부품의 업그레이드를 넘어, 공급망 전체에 걸쳐 고부가가치 기술 혁신을 강제하는 '가치 파급 효과(Value Cascade)'를 일으킵니다. 최상위의 스위치 칩(ASIC)이 3nm급 미세 공정을 요구하면, 그 칩을 실장하는 스위치 기판(PCB)은 신호 간섭을 막기 위한 고다층화 및 저유전율 소재 기술의 중요성이 커집니다. 또한, 입출력(I/O) 병목 현상을 해결하기 위한 CPO(Co-packaged Optics)와 같은 첨단 패키징 기술 도입이 가속화되고, 광 트랜시버, 케이블, 커넥터 등 생태계를 구성하는 모든 부품의 동반 기술 발전과 가격 상승을 견인하고 있습니다.

### 3.2. 글로벌 핵심 수혜 기업

완제품 장비, 시스템, 특수 부품 시장에서는 기술력과 시장 지배력을 갖춘 글로벌 기업들이 AI 네트워크 혁명을 주도하고 있습니다.

![](https://contents-resource.us-insight.com/dev/image/png/7bcddc14/1766829585179_7bcddc14__2.19272__rtcJG4g3OlmLiAh5h5RwOAk?w=1080)

**핵심 플레이어 (Main Players):**

- **광 트랜시버:** Lumentum, Coherent, Innolight, Broadcom
- **DSP/칩:** Credo, Marvell, Broadcom
- **CPO/시스템 통합:** Nvidia, Intel, Broadcom, Arista

다소 어렵죠? 밸류체인을 이해하기는 쉽지 않다고 봅니다.

**아래는 각 기업들에 대해 짧은 분석 및 밸류에이션을 첨부합니다.**

안의 종목들 중, 테크분석 및 펀더멘탈 심층 분석을 해서 보고서로 만들고 싶었지만, 너무 양이 많아져서 브리프 형태로 올리겠습니다.

***추후, 조금 더 좋은 종목과 시기가 온다면 하나씩 세부 분석을 하도록 하겠습니다.***

---

### 셀레스티카 (CLS.US): White Box 스위치의 경쟁력 부각

![](https://contents-resource.us-insight.com/dev/image/png/5e4f0303/1766829605695_5e4f0303__1.77778__+vcFBICH67NGd5dfh5qGf0f3Jw?w=1080)

데이터센터 네트워킹계의 'Foxconn'으로 비유되는 ODM 업체입니다. 하이퍼스케일러들이 직접 설계한 맞춤형 스위치(화이트박스)를 생산하며 시장 점유율을 빠르게 확대하고 있습니다.

- **핵심 제품/기술:** 맞춤형 화이트박스(White Box) 스위치
- **시장 내 포지션:** 하이퍼스케일러 맞춤형 스위치 ODM 생산을 통한 시장 점유율 확대 (데이터센터 네트워킹계의 'Foxconn')
- **핵심 성장 동력:** 강력한 800G 수요 가속화(2H25), 1.6T 관련 매출 발생 전망(2H26~)
- **주가**
![](https://contents-resource.us-insight.com/dev/image/png/b60741cf/1766829615706_b60741cf__1.5636__PQgCBIBGh5c2dnYFenKgpQJaKQ?w=1080)

**투자 리스크**

- **고객 집중도:** 매출의 상당 부분이 Meta, Microsoft 등 소수 하이퍼스케일러에 의존. 한두 고객의 Capex 조정이 실적에 큰 영향
- **ODM 마진 압박:** 화이트박스 스위치는 기본적으로 저마진 사업. 규모 확대 없이는 수익성 개선 한계
- **관세/공급망 리스크:** 중국·멕시코 등 해외 생산 비중이 높아 관세 정책 변화에 취약
- **높아진 밸류에이션:** Forward P/E 34.6x로 ODM 업체치고는 프리미엄. 실적 부진 시 멀티플 압축 가능성

---

**아리스타 네트웍스 (**[**ANET.US**](http://anet.us/)**): AI 이더넷 네트워크 장비의 승자**

![](https://contents-resource.us-insight.com/dev/image/png/f3e73762/1766829651890_f3e73762__1.77778__9/cFDICYQ6eHaXVvdLToPF/u8Q?w=1080)

개방형 이더넷 진영이 AI 백엔드 시장에서 점유율을 확대하는 흐름의 중심에 있는 기업으로, **AI 스케일아웃 환경에 최적화된 고성능 이더넷 스위치 포트폴리오를 보유한 강자입니다.** 저지연, 고확장성, 그리고 안정적인 운영체제(EOS)를 강점으로 백엔드 네트워킹 시장을 장악하고 있습니다.

**브로드컴, 마벨과 함께 ==네트워킹 시장의 초강자== 입니다.**

![](https://contents-resource.us-insight.com/dev/image/png/44502ccc/1766876171941_44502ccc__1.83184__9PcFBID2VsZ6pF2arHyvZZy/iA?w=1080)
- **핵심 제품/기술:** AI 스케일아웃 환경에 최적화된 고성능 이더넷 스위치 및 운영체제(EOS)
- **시장 내 포지션:** AI 데이터센터용 이더넷 스위치 시장의 선두주자
- **핵심 성장 동력:** 2025년 AI 네트워킹 매출 15억 달러 상회 예상, 유럽과 중동의 소버린 AI 프로젝트에 따른 해외 매출 고성장
![](https://contents-resource.us-insight.com/dev/image/png/4f1a7714/1766829668658_4f1a7714__1.79021__+/cFDIKVmXeBiHh0d2CmYGEJFg?w=1080) ![](https://contents-resource.us-insight.com/dev/image/png/a56035ee/1766829685105_a56035ee__1.55677__PggCBYB3p6Ykd5cIqQVZqpCxASgK?w=1080)

**투자 리스크**

- **높은 기대치 부담:** 2025년 YTD +40% 급등 후 실적 발표마다 '기대치 충족 여부'가 주가 변동의 핵심 변수
- **관세 불확실성:** 경영진이 관세 영향을 직접 언급하며 FY25 가이던스를 보수적으로 유지
- **서비스 vs 제품 믹스:** 제품 매출이 예상 하회 시 주가 조정 가능성(최근 실적 후 7% 하락 사례)
- **경쟁 심화:** Nvidia InfiniBand가 여전히 백엔드 시장 80%+ 점유. 이더넷 전환 속도가 관건

---

### 코히런트 (COHR.US): 초고속 광 트랜시버 시장 선도

![](https://contents-resource.us-insight.com/dev/image/png/e25b6f43/1766829705800_e25b6f43__1.77778__+AcCDIKWt2MOdaY7kXVggQcImw?w=1080)

네트워크 인프라의 필수 부품인 광 트랜시버를 제조하는 핵심 기업입니다. 레이저 소자부터 최종 조립까지 아우르는 수직계열화를 통해 독보적인 기술 및 가격 경쟁력을 확보했습니다.

- **핵심 제품/기술:** 800G, 1.6T 등 초고속 광 트랜시버
- **시장 내 포지션:** 광학 부품 시장 점유율 20% 이상을 차지하는 선도 기업, 수직계열화를 통한 기술 및 가격 경쟁력
- **핵심 성장 동력:** AI 데이터센터 투자 확대로 인한 초고속 트랜시버 수요 급증, 1.6T 트랜시버 출하 시작
- **주가**
![](https://contents-resource.us-insight.com/dev/image/png/e0ae1b9c/1766829718963_e0ae1b9c__1.53478__PggCBYB0eYghl3YDfDlUhsCWAGwJ?w=1080)

**투자 리스크**

- **대주주 매도 압박:** Bain Capital이 지분 매각 움직임을 보이며 수급 불안 요소로 작용
- **가이던스 민감도:** 실적 자체보다 다음 분기 가이던스가 주가에 더 큰 영향(FY25 Q4 가이던스 미스로 20% 급락 사례)

---

### 루멘텀 홀딩스 (LITE.US): 광 트랜시버의 또 다른 강자

![](https://contents-resource.us-insight.com/dev/image/png/026bec71/1766829739416_026bec71__1.75342__NfgFBICUqLRpdqh/mYSUhW82+A?w=1080)

코히런트(Coherent)와 함께 AI 데이터센터용 고속 광 트랜시버 시장을 양분하는 핵심 기업입니다. 200G/lane EML 레이저 기술에서 업계 리더십을 보유하고 있습니다.

- **핵심 제품/기술:** CloudLight™ 800G/1.6T OSFP 트랜시버, 200G/lane EML 레이저, R300 OCS(광 회로 스위치)
- **시장 내 포지션:** 광 트랜시버 투톱(vs Coherent), Nvidia CPO 생태계 공식 파트너
- **최근 실적:** 1Q26 매출 5.34억 달러(+58% YoY), AI/클라우드 매출 비중 60% 이상으로 확대
- **핵심 성장 동력:** 800G→1.6T 전환 사이클 수혜, 하이퍼스케일러 직접 공급 비중 확대, OCS 사업으로 시스템 레벨까지 확장
- 주가
![](https://contents-resource.us-insight.com/dev/image/png/2a1a66a1/1766829750802_2a1a66a1__1.52043__PggCBYA2l5gFhpcCZwhXVqCzBDpb?w=1080)

**투자 리스크**

- **==극단적 밸류에이션:==** ==Forward P/E 44x, EV/EBITDA 196x로 업계 최고 수준. 애널리스트들이 20~40% 하방 리스크 경고==
- **2025년 200%+ 급등 후 조정 압력:** YTD 수익률이 Nvidia를 상회할 정도로 급등. 차익 실현 매물 출회 가능성
- **AI 수요 집중 리스크:** 매출의 60%+가 AI/클라우드에 편중. AI 투자 사이클 둔화 시 직격탄

**Coherent vs Lumentum 한눈에 비교**

- **Coherent:** 레이저 소자→최종 조립까지 '풀스택 수직계열화', Datacom 점유율 20%+, 규모의 경제 강점
- **Lumentum:** 200G/lane EML 기술 리더십, Nvidia CPO 파트너, 트랜시버→OCS로 사업 확장 중, **AI 매출 비중** 더 집중적(60%+)
- 개인적 의견으로는, 밸류에이션상 코히어런트가 비교적 저렴해보입니다. 둘 다 너무 유망한 기업입니다. 광스위치 및 트랜시버에서 상당한 기술력을 보여주고 있습니다. 하지만! 미래 밸류를 많이 당겨왔다고 생각이 듭니다. **혹시 매수하실 분들은 꼭 큰 조정이 있고 조금씩 사시는 걸 추천드립니다.**

---

### 암페놀 (APH.US): 커넥터와 케이블에 날개를 달다

![](https://contents-resource.us-insight.com/dev/image/png/416a2672/1766829791992_416a2672__1.77778__+PcFBIDFVHsopIp/s7v6aJ2f1Q?w=1080)

칩, 서버, 스위치 등 데이터센터의 모든 구성 요소를 연결하는 **고성능 커넥터와 케이블** 을 생산합니다. AI 관련 수요가 IT/데이터센터 부문 성장의 약 2/3를 차지할 정도로 핵심적인 역할을 하고 있습니다.

- **핵심 제품/기술:** 저지연, 저전력 고성능 **커넥터 및 케이블**
- **시장 내 포지션:** 고성능 커넥터 및 케이블 분야의 강자, AI가 IT/데이터센터 부문 성장의 핵심 동력
- **핵심 성장 동력:** 고부가가치 제품군 확대, CommScope 사업 인수를 통한 광섬유 케이블 솔루션 포트폴리오 강화
- **주가**
![](https://contents-resource.us-insight.com/dev/image/png/bf7b964f/1766829797433_bf7b964f__1.50649__PQgCBYBnaIokl4cGjCqIpZCnAmkq?w=1080)

가장 강력한 커넥터, 케이블 기업입니다.

**투자 리스크**

- **==높은 밸류에이션:==** ==Forward P/E 33.6x로 커넥터 업종 평균 대비 프리미엄. 12개월간 90% 상승 후 추가 상승 여력에 의문==
- **M&A 통합 부담:** CommScope 등 대형 인수 후 통합 비용 및 시너지 실현 시간 필요
- **원자재 가격 변동:** 구리 가격 급등 등 핵심 원자재 가격 상승 시 마진 압박 가능성

---

### 시스코 시스템즈 (CSCO.US): 네트워킹의 모든 것

![](https://contents-resource.us-insight.com/dev/image/png/b3f35a29/1766829814542_b3f35a29__1.77778__9gcGBIDecsJkaYtbeIBzjCCmBw?w=1080)

글로벌 네트워크 장비 시장 1위 기업으로, 풀스택 솔루션과 강력한 기술 지원(TAC)을 기반으로 높은 고객 락인(Lock-in) 효과를 자랑합니다.

- **핵심 제품/기술:** 풀스택 네트워킹 장비, 보안 솔루션 (Catalyst 9000 시리즈 등)
- **시장 내 포지션:** 글로벌 1위의 네트워크 장비 기업, 강력한 기술 지원(TAC)을 통한 높은 고객 락인 효과
- **핵심 성장 동력:** 기업들의 업무용 AI 확산에 따른 보안·안정성 중심의 네트워크 수요 증가, 주력 제품의 교체 주기 도래
- **주가**
![](https://contents-resource.us-insight.com/dev/image/png/dc734cdb/1766829825418_dc734cdb__1.52278__PQgCBYCFaZcXd3UCaGhYuqKQEggZ?w=1080)

풀스택 솔루션을 지원하는, 네트워킹 장비의 터줏대감입니다. 다들 닷컴버블예시로 잘 아실 기업입니다. 다만, 너무 다양한 포트폴리오와 그렇게 높지 않은 성장률이 아쉽습니다.

**투자 리스크**

- **==성장률 한계:==** ==매출 성장률이 한 자릿수에 그치는 성숙 기업. AI 순수 플레이어 대비 성장 모멘텀 약함==
- **AI 사업 비중 미미:** AI 관련 주문($13억)이 전체 매출 대비 아직 작은 비중. AI 테마 수혜 제한적
- **경쟁 심화:** Arista, Juniper 등이 클라우드·AI 시장에서 점유율 잠식 중
- **Splunk 인수 부담:** 280억 달러 인수 후 통합 비용 및 시너지 실현이 과제

---

### 크레도 테크놀로지 (CRDO.US): 초저전력 DSP의 신흥 강자

![](https://contents-resource.us-insight.com/dev/image/png/38e43159/1766829861406_38e43159__1.87203__+fcFBICFWvlGVndtdZeAewiohw?w=1080)

800G/1.6T 광 트랜시버의 핵심 부품인 **광 DSP(Digital Signal Processor)** 전문 기업입니다.

- **핵심 제품:** Lark (800G), Bluebird (1.6T) 광 DSP 제품군, HiWire AEC(Active Electrical Cable)
- **차별점:** 업계 최저 수준의 전력 소모량으로 AI 백엔드 네트워크에 특화
- **최근 동향:** 2025년 1.6T Bluebird DSP 출시, AI 스케일아웃 패브릭용 솔루션 적극 전개
- **투자 포인트:** 800G→1.6T 전환 사이클의 핵심 수혜주로, 광 트랜시버 제조사(Coherent, Innolight 등)에 DSP를 공급
- **주가**
![](https://contents-resource.us-insight.com/dev/image/png/d1bd3e2c/1766829873573_d1bd3e2c__1.47458__PQgCBYCIqJclmGYIqkZ42JGVEFkJ?w=1080)

**투자 리스크**

- **==극단적 밸류에이션:==** ==EV/EBITDA 117x로 업계 최고 수준. 고성장이 이미 주가에 반영됨==
- **고객 집중도:** 소수 대형 고객 의존도 높음. 주요 고객사 물량 변동에 실적이 크게 좌우
- **경쟁 심화:** Broadcom, Marvell이 DSP 시장에서 공격적으로 확장 중
- **재무 안정성:** 고성장 국면이지만 아직 재무 기반이 대형주 대비 취약

---

### 마벨 테크놀로지 (MRVL.US): AI 인터커넥트 올인원 플레이어

![](https://contents-resource.us-insight.com/dev/image/png/f0d72b1f/1766829894528_f0d72b1f__1.88582__+PcFBICTvflWpph6doiAaCaABw?w=1080)

Celestial AI를 최대 **55억 달러에 인수** 하며 광 인터커넥트 역량을 대폭 강화한 종합 반도체 기업입니다.

- **핵심 제품:** 광 DSP, 실리콘 포토닉스 라이트 엔진, 데이터센터 스위치 ASIC
- **차별점:** DSP부터 실리콘 포토닉스까지 수직계열화, 커스텀 AI 칩 설계 역량도 보유
- **최근 동향:** 1.6T 실리콘 포토닉스 라이트 엔진 시연(OFC 2025), 랙-스케일 AI 서버 배포 지원
- **투자 포인트:** Celestial AI 인수로 차세대 광 인터커넥트 기술 확보, AI 데이터센터의 "신경계" 구축 목표
- **주가**
![](https://contents-resource.us-insight.com/dev/image/png/347ebd07/1766829900560_347ebd07__1.54267__/vcBBYAwl6knhndkiAhVaUR/S/Wm?w=1080)

**투자 리스크**

- **==Broadcom과의 ASIC 경쟁:==** ==HSBC 등 애널리스트들이 "Broadcom이 ASIC 시장에서 더 강한 모멘텀 보유"라고 경고==
- **데이터센터 가이던스 부진:** 분기별 가이던스가 시장 기대치 하회 시 급락(최근 12%+ 하락 사례)
- **Celestial AI 인수 통합:** $55억 규모 인수의 시너지 실현에 수년 소요. 단기 비용 부담
- **비AI 사업부 부진:** 커스텀 칩·스토리지 등 비AI 부문 회복 지연

---

### 브로드컴 (AVGO.US): CPO 기술의 선구자

![](https://contents-resource.us-insight.com/dev/image/png/f3b61aef/1766829922739_f3b61aef__1.83184__+PcFDIBkyYhbh2ZvhnWgiwvLqA?w=1080)

AI 반도체뿐 아니라 **CPO(Co-packaged Optics)** 분야에서도 기술 리더십을 확보한 대형 반도체 기업입니다.

- **핵심 제품:** 3세대 CPO 기술(200G/lane), 스위치 ASIC (Memory, Tomahawk 시리즈)
- **차별점:** 200T 광 인터커넥트 로드맵 제시, CPO 생태계 성숙도 업계 최고 수준
- **최근 동향:** OFC 2025에서 200G/lane CPO 기술 및 PCIe Gen6 over optics 시연
- **투자 포인트:** AI ASIC 매출 급성장 + 네트워크 칩 + CPO 삼박자를 갖춘 종합 수혜주
- **주가**
![](https://contents-resource.us-insight.com/dev/image/png/deab5726/1766829928720_deab5726__1.53611__PQgCBYBliXYZlnYDrCl4xXGjACgK?w=1080)

**투자 리스크**

- **AI 마진 압박:** AI 관련 매출 급증에도 그로스 마진에 대한 우려 제기. 최근 실적 후 11% 급락
- **높은 기대치:** 시총 $1.6T로 "완벽한 실적"이 아니면 시장 실망. 가이던스가 조금만 보수적이어도 주가 하락
- **고객 집중도:** AI ASIC 매출 대부분이 Google, Meta 등 소수 하이퍼스케일러에 의존
- **과거 급락 전례:** 2개월 내 30%+ 급락이 최근 수년간 2회 발생. 변동성 주의

---

## 주요 기업 밸류에이션 지표 비교

<table><colgroup><col> <col> <col> <col> <col> <col></colgroup><tbody><tr><td colspan="1" rowspan="1"><p><strong>회사</strong></p></td><td colspan="1" rowspan="1"><p><strong>티커</strong></p></td><td colspan="1" rowspan="1"><p><strong>종가</strong></p></td><td colspan="1" rowspan="1"><p><strong>시가총액</strong></p></td><td colspan="1" rowspan="1"><p><strong>Forward P/E</strong></p></td><td colspan="1" rowspan="1"><p><strong>EV/EBITDA</strong></p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Celestica</strong></span></p></td><td colspan="1" rowspan="1"><p>CLS</p></td><td colspan="1" rowspan="1"><p>$292.29</p></td><td colspan="1" rowspan="1"><p>$33.63B</p></td><td colspan="1" rowspan="1"><p>34.60x</p></td><td colspan="1" rowspan="1"><p>30.53x</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Arista</strong></span></p></td><td colspan="1" rowspan="1"><p>ANET</p></td><td colspan="1" rowspan="1"><p>$131.12</p></td><td colspan="1" rowspan="1"><p>$165.12B</p></td><td colspan="1" rowspan="1"><p>38.96x</p></td><td colspan="1" rowspan="1"><p>42.03x</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Coherent</strong></span></p></td><td colspan="1" rowspan="1"><p>COHR</p></td><td colspan="1" rowspan="1"><p>$185.83</p></td><td colspan="1" rowspan="1"><p>$29.20B</p></td><td colspan="1" rowspan="1"><p>28.85x</p></td><td colspan="1" rowspan="1"><p>29.01x</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Amphenol</strong></span></p></td><td colspan="1" rowspan="1"><p>APH</p></td><td colspan="1" rowspan="1"><p>$135.29</p></td><td colspan="1" rowspan="1"><p>$165.60B</p></td><td colspan="1" rowspan="1"><p>33.64x</p></td><td colspan="1" rowspan="1"><p>28.38x</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Cisco</strong></span></p></td><td colspan="1" rowspan="1"><p>CSCO</p></td><td colspan="1" rowspan="1"><p>$78.42</p></td><td colspan="1" rowspan="1"><p>$309.84B</p></td><td colspan="1" rowspan="1"><p>17.50x</p></td><td colspan="1" rowspan="1"><p>20.37x</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Credo</strong></span></p></td><td colspan="1" rowspan="1"><p><span>CRDO</span></p></td><td colspan="1" rowspan="1"><p><span>$150.13</span></p></td><td colspan="1" rowspan="1"><p><span>$27.12B</span></p></td><td colspan="1" rowspan="1"><p><span>41.86x</span></p></td><td colspan="1" rowspan="1"><p><span>116.93x</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Marvell</strong></span></p></td><td colspan="1" rowspan="1"><p>MRVL</p></td><td colspan="1" rowspan="1"><p>$84.09</p></td><td colspan="1" rowspan="1"><p>$71.32B</p></td><td colspan="1" rowspan="1"><p>23.47x</p></td><td colspan="1" rowspan="1"><p>30.10x</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Broadcom</strong></span></p></td><td colspan="1" rowspan="1"><p>AVGO</p></td><td colspan="1" rowspan="1"><p>$340.36</p></td><td colspan="1" rowspan="1"><p>$1.61T</p></td><td colspan="1" rowspan="1"><p>30.28x</p></td><td colspan="1" rowspan="1"><p>47.64x</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>Lumentum</strong></span></p></td><td colspan="1" rowspan="1"><p><span>LITE</span></p></td><td colspan="1" rowspan="1"><p><span>$371.43</span></p></td><td colspan="1" rowspan="1"><p><span>$26.33B</span></p></td><td colspan="1" rowspan="1"><p><span>44.40x</span></p></td><td colspan="1" rowspan="1"><p><span>196.37x</span></p></td></tr></tbody></table>

전반적으로 밸류에이션이 상당히 높은 편입니다. 특히 Credo, Lumentum 같은 경우는 정말 많이 올랐습니다. 저도 정찰병으로 보낸 녀석(ㅠㅠ)들이 가장 많이 올라버려서 많이 배가 아픕니다. 하지만 어떻게 합니까? 이미 오른 건 제 몫이 아니었다고 생각합니다.

위의 네트워크 장비들은 앞으로 수년간 엄청난 성장을 할 기업들입니다. 주가는 성장 프리미엄을 가득 머금은 상태이구요.

**최근 브로드컴 조정처럼 고점대비 확 빠졌을 때 조금씩 치고 들어가는 방향이 좋아 보입니다.**

\-20%일 때부터, -40%까지 시나리오를 차분히 세운 후, 분할매수로 6개월에서 1년을 보고 들어가셔야 합니다.

물론, 매수 시 펀더멘탈에 문제가 있는지도 한 번 꼭 확인해 보셔야 합니다.

---

## 결론: 종합 정리 및 최종 인사이트

**AI 투자 패러다임은 돌이킬 수 없는 변화를 맞이했습니다.**

더 많은 연산 자원을 확보하는 경쟁을 넘어, 이제는 투자 효율성을 극대화하기 위한 네트워크 중심의 경쟁으로 전환되었습니다. 이는 AI 기술의 성숙과 함께 찾아온 필연적인 흐름입니다.

본 보고서의 핵심 결론은 다음과 같습니다.

1. **==효율성의 시대==:** AI 투자의 성공 방정식은 이제 TCO와 OpEx를 고려한 효율성 극대화이며, 그 전략의 중심에는 고성능 네트워크가 자리 잡고 있습니다.
![](https://contents-resource.us-insight.com/dev/image/png/ba7550df/1766830009481_ba7550df__1.77778__OAgGDIL6qIaJWWVaqHgfasiQRw?w=1080)
1. **==기술의 상향 평준화==:** 800G를 넘어 1.6T로 향하는 네트워크 속도 경쟁은 AI 성능과 직결되며, 이는 스위치, 기판, 소재, 광학 부품 등 관련 생태계 전반의 동반 성장을 견인할 것입니다.
![](https://contents-resource.us-insight.com/dev/image/png/26f84a7e/1766830013475_26f84a7e__1.77778__+fcFDID5Jlh6d4drpoP5ipy/yA?w=1080)
1. **==생태계 경쟁 심화==:** Nvidia의 독점적 지위에 도전하는 '개방형 이더넷' 진영의 성장이 가속화될 것입니다. 이는 장기적으로 소비자에게 더 많은 선택권과 비용 효율성을 제공하며 시장을 더욱 건강하게 만들 것입니다.
![](https://contents-resource.us-insight.com/dev/image/png/1fe63b26/1766830017775_1fe63b26__1.77778__tPcJDILlmVqKZoifVYbre7/N9w?w=1080)

> **AI라는 거대한 파도가 휩쓸고 간 자리에, 이제는 '옥석'을 가리는 시간이 왔습니다.** 누가 더 많은 GPU를 가졌는지가 중요했던 1차전이 끝났고, 이제 그 GPU를 얼마나 똑똑하게 활용하는지를 겨루는 2차전이 시작된 것이죠.
> 
> **이 게임의 규칙을 바꾸는 키는 바로 '네트워크'입니다.** 앞으로 우리는 AI 기업을 평가할 때, 단순히 모델의 성능뿐만 아니라 그들의 데이터센터 네트워크 아키텍처와 효율성을 함께 들여다봐야 할 겁니다. 진정한 강자는 가장 비싼 무기를 가진 자가 아니라, 가진 무기를 가장 효율적으로 쓰는 자가 될 테니까요. 이 거대한 흐름 속에서 기회를 잡는 기업들에 주목해야 할 때입니다.

  

***==보너스 심화편(아래는 기술적인 내용이 많이 나오니 생략해도 좋습니다.)==***

25.3월 Semi analysis에서 분석한 엔비디아 GB200 NVL72에 관한 아티클. 당시에도 구리선으로 인해 광학 케이블과 스위치가 위협이 될 것이다라는 분석이 있었지만, Semi-Analysis측의 반박이 나왔습니다.

**==“광케이블과 스위치 수요는 늘 것이다”==**

**실제로 그렇게 이루어졌습니다.**

---

## 엔비디아 GB200 NVL72, 광학 업계의 위기인가?

- **젠슨 황**
![](https://substackcdn.com/image/fetch/$s_!slCM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9dc1f225-78eb-4313-bddf-6e3e05f78127_2396x1248.png?w=1080)

**GB200 NVL72의 구조**

기존 AI 서버는 8개 GPU가 표준이었습니다. GB200 NVL72는 완전히 다릅니다.

**단일 랙에 통합된 구성:**

- GPU 72개
- CPU 36개
- NVSwitch 18개
- 백엔드용 InfiniBand NIC 72개
- 프론트엔드용 Bluefield 3 이더넷 NIC 36개
![](https://substackcdn.com/image/fetch/$s_!KdlG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc40e4946-a6b2-4053-bfa0-09b3a8f252de_4032x3024.jpeg?w=1080)

---

## 광학 시장의 오해: 구리가 광학을 대체한다?

NVSwitch 하나당 288개의 구리 케이블이 연결됩니다. 총 5,184개의 구리선이 72개 GPU를 묶습니다.

일부 투자자들은 이렇게 해석했습니다.

- NVLink가 랙 내부 GPU를 모두 연결하니, 외부 광학 장비가 줄어들겠다
- 광학 트랜시버 수요가 감소할 것이다

**결론부터 말하면, 틀렸습니다.**

![](https://substackcdn.com/image/fetch/$s_!mCb9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0e64656-fc49-409b-a401-c3979812fd8b_2480x1456.png?w=1080)

---

## 세 가지 네트워크의 병존

DGX H100이든 GB200 NVL이든, AI 클러스터는 세 가지 네트워크를 동시에 사용합니다.

<table><colgroup><col> <col> <col></colgroup><tbody><tr><td colspan="1" rowspan="1"><p><strong>네트워크</strong></p></td><td colspan="1" rowspan="1"><p><strong>역할</strong></p></td><td colspan="1" rowspan="1"><p><strong>연결 비율</strong></p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>프론트엔드 이더넷</strong></span></p></td><td colspan="1" rowspan="1"><p>외부 통신, 관리용</p></td><td colspan="1" rowspan="1"><p>GPU 2~4개당 NIC 1개</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>백엔드 InfiniBand/이더넷</strong></span></p></td><td colspan="1" rowspan="1"><p>스케일 아웃(클러스터 간)</p></td><td colspan="1" rowspan="1"><p>GPU 1개당 NIC 1개</p></td></tr><tr><td colspan="1" rowspan="1"><p><span><strong>NVLink</strong></span></p></td><td colspan="1" rowspan="1"><p>스케일 업(랙 내부)</p></td><td colspan="1" rowspan="1"><p>8개 또는 72개 GPU 연결</p></td></tr></tbody></table>

![](https://substackcdn.com/image/fetch/$s_!n4Rv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41f6bfad-c9b3-40d2-90ea-06418048f45f_1225x990.png?w=1080)

---

## 광학 트랜시버, 여전히 필수

GTC에서 선보인 NVL72 랙에는 400G/800G OSFP 포트가 72개 있습니다. GPU 하나당 광학 포트 하나입니다.

H100 시절과 동일한 비율입니다. 달라진 게 없습니다.

- GPU 클러스터가 커지면? 광학 트랜시버도 비례해서 늘어납니다
- NVL72 랙 하나만 구매할 이유는 없습니다
- 대규모 클러스터에는 반드시 스케일 아웃 네트워크가 필요합니다
![](https://substackcdn.com/image/fetch/$s_!ZXqE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2deb5e62-4783-4975-a6ff-9f0b694c38f9_1495x895.png?w=1080)

> "NVL72가 광학을 죽인다는 건 착각입니다. 랙 내부는 구리, 랙 외부는 광학. 역할 분담이 명확해진 것뿐이죠. 오히려 클러스터 규모가 커질수록 광학 수요는 늘어납니다. 구리와 광학은 대체재가 아니라 보완재입니다."

---

## Clos 네트워크의 이해

대규모 GPU 클러스터는 **Clos 논블로킹 팻 트리 네트워크** 를 사용합니다.

**Clos 네트워크란?**

전화 교환 시스템에서 유래한 설계 방식입니다. 핵심은 두 가지입니다.

1. **확장성**: 노드가 늘어나도 복잡도가 급증하지 않습니다
2. **다중 경로**: A에서 B로 가는 길이 여러 개여서 병목이 줄어듭니다

공항 터미널을 생각해 보세요. 게이트(리프 스위치)와 중앙 허브(스파인 스위치)가 여러 통로로 연결되어 있으면, 한 곳이 막혀도 다른 길로 갈 수 있습니다.

![](https://substackcdn.com/image/fetch/$s_!h5BY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecbfceb9-c3de-4153-b969-710f9788651a_2064x790.png?w=1080)

---

## 레일 최적화: GPU 연결의 핵심 전략

전통적인 "랙 상단(Top of Rack)" 방식은 같은 랙의 GPU를 같은 스위치에 연결합니다.

엔비디아의 **레일 최적화 아키텍처** 는 다릅니다.

- 서버 내 GPU들을 의도적으로 다른 리프 스위치에 분산 연결합니다
- 이유: 서버 내부 NVLink가 대체 경로를 제공하기 때문입니다
![](https://substackcdn.com/image/fetch/$s_!V8c4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F468053db-65b0-4756-b8c7-c6ffb39ddf49_1371x808.png?w=1080)

**장점:**

- 스파인 레벨을 거치지 않고도 데이터 전송 가능
- 홉(경유) 수 감소
- 전체 네트워크 효율 향상

**단점:**

- 노드에서 리프 스위치까지 거리가 길어짐
- 3미터 수동 구리 케이블로는 부족
- 결국 광학 트랜시버가 필요
![](https://substackcdn.com/image/fetch/$s_!7voq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c36e840-c907-47b7-95de-e8c255014cd7_1617x376.png?w=1080)

> "레일 최적화는 NVLink와 InfiniBand의 장점을 동시에 취하는 전략입니다. 가까운 건 구리로, 먼 건 광학으로. 합리적인 선택이죠."

---

## 네트워크 계층 구조

512개 GPU 네트워크 구축을 예로 들어보겠습니다.

**리프 스위치 계산:**

- Quantum-2 QM9700 스위치: 32개 OSFP 케이지, 64개 400G 포트
- 512개 노드 / 스위치당 32포트 = 리프 스위치 16개 필요

**스파인 스위치 연결:**

- 각 리프 스위치는 모든 스파인 스위치에 연결
- 4개 링크 묶음으로 8개 스파인 스위치 구성
![](https://substackcdn.com/image/fetch/$s_!K9AK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40bd40c2-7bc4-4893-b3d0-2a19dbe69bb2_1621x346.png?w=1080)

**2계층 네트워크의 한계:**

- 64포트 스위치 기준, 최대 2,048개 GPU까지만 가능
- 그 이상은 코어 스위치 계층(3계층) 필요
- 네트워크 복잡성과 비용 급증
![](https://substackcdn.com/image/fetch/$s_!JBiA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb7670c-477a-44b6-8e9f-c7d39e7a13ca_2178x784.png?w=1080)

---

## 진짜 위협: 144포트 Quantum-X800 스위치

모두가 NVL72에 집중하는 사이, 진짜 변화는 따로 있었습니다.

**Quantum-X800 Q3400-RA 4U 스위치:**

- 72개 OSFP 포트로 144개 800G 포트 제공
- 1.6T 듀얼 포트 트랜시버 사용
- 총 라딕스: 115.2Tbps
- 기존 Quantum-2(25.6Tbps) 대비 **==4배 이상==**
![](https://substackcdn.com/image/fetch/$s_!zHeL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28aa608a-6f69-4cac-8495-69c7842a8c39_4032x3024.jpeg?w=1080)

**라딕스(Radix)란?**

스위치가 처리할 수 있는 총 대역폭입니다. 라딕스가 클수록 더 많은 데이터를 동시에 처리합니다. 고속도로 차선 수와 비슷합니다. 차선이 많을수록 더 많은 차가 동시에 달릴 수 있죠.

---

## 144포트 스위치의 파급력

**2계층 네트워크 확장:**

- 64포트 스위치: 최대 2,048개 GPU
- 144포트 스위치: 최대 **10,368개 GPU**
- 약 5배 확장
![](https://substackcdn.com/image/fetch/$s_!_Rkp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd450cbcd-9a3c-4e01-9b60-4d7e3429a0d2_2217x798.png?w=1080)

  

**9,000개 GPU 클러스터 비교:**

<table><colgroup><col> <col> <col> <col></colgroup><tbody><tr><td colspan="1" rowspan="1"><p><strong>항목</strong></p></td><td colspan="1" rowspan="1"><p><strong>64포트 스위치</strong></p></td><td colspan="1" rowspan="1"><p><strong>144포트 스위치</strong></p></td><td colspan="1" rowspan="1"><p><strong>절감률</strong></p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>네트워크 계층</strong></p></td><td colspan="1" rowspan="1"><p>3계층</p></td><td colspan="1" rowspan="1"><p>2계층</p></td><td colspan="1" rowspan="1"><p>-</p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>스위치 수</strong></p></td><td colspan="1" rowspan="1"><p>기준</p></td><td colspan="1" rowspan="1"><p>30%</p></td><td colspan="1" rowspan="1"><p><span><strong>70% 절감</strong></span></p></td></tr><tr><td colspan="1" rowspan="1"><p><strong>트랜시버 수</strong></p></td><td colspan="1" rowspan="1"><p>기준</p></td><td colspan="1" rowspan="1"><p>73%</p></td><td colspan="1" rowspan="1"><p><span><strong>27% 절감</strong></span></p></td></tr></tbody></table>

![](https://substackcdn.com/image/fetch/$s_!GE5C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9928d3f-f495-4615-a6c8-95dd397524cd_1041x919.png?w=1080)

> "모두가 구리 케이블에 놀라는 동안, 144포트 스위치가 조용히 판을 바꿨습니다. 네트워크 계층이 줄어들면 복잡성이 줄고, 비용이 줄고, 장애점도 줍니다. 진짜 게임 체인저는 여기에 있었죠."

---

## 800G에서 1.6T로: ASP 상승의 기회

ConnectX-8(800G)과 Quantum-X800을 선택하면 광학 물량은 줄어듭니다.

하지만 단위당 가격(ASP)은 올라갑니다.

- NIC 포트: 400G → 800G
- 스위치 포트: 800G → 1.6T
![](https://substackcdn.com/image/fetch/$s_!apJM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F059f7de3-df58-4e2a-b0c0-0e89185e7286_1494x895.png?w=1080)

**ASP(Average Selling Price)란?**

평균 판매 가격입니다. 물량이 줄어도 단가가 오르면 매출은 유지되거나 늘어날 수 있습니다. 광학 업계 입장에서는 "적게 팔아도 비싸게 팔 수 있는" 구조로의 전환입니다.

---

## 종합 정리

### 핵심 포인트

1. **NVL72의 구리 케이블은 랙 내부 전용입니다**
	- 랙 간 연결은 여전히 광학 트랜시버가 담당
2. **GPU당 광학 포트 비율은 변함없습니다**
	- 클러스터가 커지면 광학 수요도 비례 증가
3. **진짜 변화는 144포트 스위치입니다**
	- 네트워크 계층 단순화
	- 스위치와 트랜시버 수 감소
4. **물량 감소 vs ASP 상승의 균형**
	- 800G/1.6T 전환으로 단가 상승
	- 광학 업체 매출 영향은 복합적

  

월텍남의 실전투자클럽

### 알파 테크 리포트

13

\[기술트렌드 & 기업 밸류에이션\]네트워크 특집: AI 경쟁의 다음 라운드, 이미 시작됐다?

12

ASIC vs GPU, 결국 살아남는 쪽은?

![월텍남의 실전투자클럽](https://us-insight.com/_next/image?url=https%3A%2F%2Fasset.us-insight.com%2Fprod%252Fadmin%252Fimage%252Fpng%252F1759382614253_c537c08a-3cc5-447b-b9e0-507f8a6e5103.png&w=3840&q=75)

## 월텍남의 실전투자클럽

세상을 바꾸는 기술을 공부합니다. 시장보다 먼저 움직이고 싶은 투자자들을 위한 인사이트를 빠르게 전해드리겠습니다.

멤버십

![cardImage](https://us-insight.com/_next/image?url=https%3A%2F%2Fresource.us-insight.com%2Fdonation%2Fprod%2FMessageCard02.png&w=750&q=75) ![user_profile](https://us-insight.com/_next/image?url=https%3A%2F%2Fresource.us-insight.com%2Fprod%2Fcommon%2FR11_aFTfidt1EanCdrHtMQG-6aq2RUxQa2pA57HDaG0%2Fprofile%2F1760488135169_profile_1760488134974&w=96&q=75)

BooSter

5000

![cardImage](https://us-insight.com/_next/image?url=https%3A%2F%2Fresource.us-insight.com%2Fdonation%2Fprod%2FMessageCard01.png&w=750&q=75)

방어가공격

10000

![cardImage](https://us-insight.com/_next/image?url=https%3A%2F%2Fresource.us-insight.com%2Fdonation%2Fprod%2FMessageCard02.png&w=750&q=75)

투자왕\_7070

10000

38

**이번 동행은 어떠셨나요?**

총 24명 참여

멤버십

프리티실버

약 3시간 전

지식을 나눔에 감사합니다.

멤버십

말룸 카에도

약 3시간 전

지식을 나눔에 감사합니다.

멤버십

투자초초딩

약 4시간 전

지식을 나눔에 감사합니다.

멤버십

멋진오뎅

약 5시간 전

투자의 지혜가 쌓여갑니다.

멤버십

투자자\_375577

약 5시간 전

사랑하는 마음을 전합니다.

멤버십

투자자\_375577

약 5시간 전

함께하여 든든합니다.

멤버십

투자자\_375577

약 5시간 전

투자의 지혜가 쌓여갑니다.

멤버십

투자자\_375577

약 5시간 전

지식을 나눔에 감사합니다.

멤버십

Lannister

약 6시간 전

지식을 나눔에 감사합니다.

멤버십

투자왕\_73683

약 7시간 전

투자의 지혜가 쌓여갑니다.

어스얼라이언스와 파트너는 금융투자업자가 아닌 유사투자자문업자로 개별적인 투자 상담과 자금 운영이 불가합니다.  
본 사이트에서 제공되는 모든 정보는 투자판단의 참고자료로 원금 손실이 발생할 수 있으며, 그 손실은 투자자에게 귀속됩니다.

어스얼라이언스주식회사 (대표이사: 김선우, 임예성) | 주소: 서울특별시 마포구 양화로 78-22, 1층(서교동) | 사업자등록번호: 119-86-49349 통신판매업 신고 번호: 제2022-서울마포-3582호 | 개인정보책임자: 김희동 uc.help@us-all.co.kr Copyright ⓒ 2025 US Alliance. All rights reserved.